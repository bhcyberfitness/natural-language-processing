{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmQAxlbNd+ma2aNPZfcarL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Aims\n",
        "\n",
        "To test multiple ML models on a dataset to refresh knowledge of commonly used python libraries including sklearn and matplotlib\n",
        "\n",
        "Much of the code is re-used from the Data Science: NLP Udemy course by The Lazy Programmer ([code](https://github.com/lazyprogrammer/machine_learning_examples/blob/master/nlp_class/nb.py))"
      ],
      "metadata": {
        "id": "Eqmm_8bzPRN-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "AlpOeFuvPOIT"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('spambase.data').to_numpy()\n",
        "np.random.shuffle(data)"
      ],
      "metadata": {
        "id": "Slb9GA7eZUNy"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split into X and Y (X is the data we want to analyse and Y is the value that specifies whether the line corresponds to a spam email or not)\n",
        "\n",
        "To get X, we specify data[:, :48]. The first colon is for the row, and a colon on its own means all rows are included. The :48 is equivalent to 0:48, and means columns 0-48, which are word frequencies.\n",
        "\n",
        "To get Y, we specify data[:, -1]. This is all rows again but the column index specifies column -1 only, which means the very last column, which is 1 for spam and 0 for not spam."
      ],
      "metadata": {
        "id": "RPDZAvSjbcFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[:, :48]\n",
        "Y = data[:, -1]"
      ],
      "metadata": {
        "id": "fUXvX560abJi"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to take 100 rows for the test set and the remainder of the rows for the train set. Since we have shuffled the array above we can simply take the bottom 100 rows as the test set.\n",
        "\n",
        "We use the index [:-100,] (equivalent to [0:-100,:]) to select all rows from the beginning to 100 from the end for train.\n",
        "\n",
        "We use the index [-100:,] (equivalent to [-100:end,:]) to select all rows from 100 from the end to the end for test."
      ],
      "metadata": {
        "id": "E8QP9f0mcS7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain = X[:-100,]\n",
        "Ytrain = Y[:-100,]\n",
        "Xtest = X[-100:,]\n",
        "Ytest = Y[-100:,]"
      ],
      "metadata": {
        "id": "UYPucrwJbbly"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a model using MultinomialNB from sklearn, fit it to the training data and score it on the test data."
      ],
      "metadata": {
        "id": "Rk2xv98FdfGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NBmodel = MultinomialNB()\n",
        "NBmodel.fit(Xtrain,Ytrain)\n",
        "print(\"Classification for NB: \"+str(NBmodel.score(Xtest,Ytest)))"
      ],
      "metadata": {
        "id": "rVmmw69odJbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gives scores in the order of 0.85-0.9, or 85-90%.\n",
        "\n",
        "We can try a different model, such as AdaBoost"
      ],
      "metadata": {
        "id": "4PHobLFNdpsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ABmodel = AdaBoostClassifier()\n",
        "ABmodel.fit(Xtrain,Ytrain)\n",
        "print(\"Classification for AdaBoost: \"+str(ABmodel.score(Xtest,Ytest)))"
      ],
      "metadata": {
        "id": "IkvUfYwSedH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running this a few times gives slightly better scores, however to visualise the performance lets run each one multiple times, compute the average score and plot the results using matplotlib."
      ],
      "metadata": {
        "id": "xJdiYknzemjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NBperformance = []\n",
        "ABperformance = []\n",
        "\n",
        "for _ in range(50):\n",
        "    np.random.shuffle(data)\n",
        "    X = data[:, :48]\n",
        "    Y = data[:, -1]\n",
        "    Xtrain = X[:-100,]\n",
        "    Ytrain = Y[:-100,]\n",
        "    Xtest = X[-100:,]\n",
        "    Ytest = Y[-100:,]\n",
        "    NBmodel.fit(Xtrain,Ytrain)\n",
        "    ABmodel.fit(Xtrain,Ytrain)\n",
        "    NBperformance.append(NBmodel.score(Xtest,Ytest))\n",
        "    ABperformance.append(ABmodel.score(Xtest,Ytest))"
      ],
      "metadata": {
        "id": "ZIrA8swIfQr-"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"NB average performance: \"+str(sum(NBperformance)/len(NBperformance)))\n",
        "print(\"AB average performance: \"+str(sum(ABperformance)/len(ABperformance)))"
      ],
      "metadata": {
        "id": "fTgqfu3Nh0ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(NBperformance)\n",
        "plt.plot(ABperformance)\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0.5,1)\n",
        "plt.legend(['Naive-Bayes','AdaBoost'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RzNLTZ1EhFs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another model we can use is a neural network, or in this specific example a multi-layer perceptron, also included in sklearn. In this example, we use a MLP with two hidden layers with 20 elements each."
      ],
      "metadata": {
        "id": "8hs48MfdpW-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NNmodel = MLPClassifier(hidden_layer_sizes=(20,20), max_iter=2000)\n",
        "NNmodel.fit(Xtrain,Ytrain)\n",
        "print(\"MLP performance: \"+str(NNmodel.score(Xtest,Ytest)))"
      ],
      "metadata": {
        "id": "bbfAYWvopWmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to the increased computational resources required for this, we won't loop this several times, however we can see performances of 93-96%, better than both Naive-Bayes and AdaBoost."
      ],
      "metadata": {
        "id": "XMVVyLpKp6WQ"
      }
    }
  ]
}