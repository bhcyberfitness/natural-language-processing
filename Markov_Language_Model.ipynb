{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQPwsIBpSlYPw8XPceim4d"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import string\n",
        "import numpy as np\n",
        "random.seed()"
      ],
      "metadata": {
        "id": "wqRBYwV8FTwN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import text from the file"
      ],
      "metadata": {
        "id": "0EnFB_XAp6sx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4Es0eZ9l3qYJ"
      },
      "outputs": [],
      "source": [
        "f = open('edgar_allan_poe.txt')\n",
        "text = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Format text into list of lines, lowercase and punctuation removed"
      ],
      "metadata": {
        "id": "HRPKc-crHUpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lines_formatted = []\n",
        "lines = text.splitlines()\n",
        "for line in lines:\n",
        "    if line:\n",
        "        lines_formatted.append(line.lower().translate(str.maketrans('', '', string.punctuation)))"
      ],
      "metadata": {
        "id": "fxbMfTp0HUS-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Iterate through lines to populate pi and A dictionaries:\n",
        "\n",
        "Pi is a dictionary where the keys are the words and the values are the probabilities.\n",
        "\n",
        "We will need two A dictionaries, one for first order probabilities, for the second word in a line, and one for second order probabilities, for the rest of the line.\n",
        "\n",
        "A1 is a dictionary where the keys are the words and the values are further dictionaries, containing probabilities for following words.\n",
        "\n",
        "A2 is a dictionary where the keys are word pairs and the values are further dictionaries as with A1.\n",
        "\n",
        "Loop through each line in all input text, and in each line loop through each word:\n",
        "\n",
        "\n",
        "*   If the word is in the first position in the line, check if it exists in Pi dictionary. If so, increment its value by 1/N where N is number of lines. If not, add it to the dictionary with value 1/N.\n",
        "*   If the word is in the second position:\n",
        "*   Check if the previous word exists in A1 dictionary. If so, check if current word exists in subdictionary. If so, increment its value by 1. If current word does not exist in subdictionary, add it with value 1. If previous word does not exist in A1 dictionary, add it and add current word to subdictionary with value 1.\n",
        "*   If the word is in any other position:\n",
        "*   Check if the previous word-pair exists in A2 dictionary. If so, check if current word exists in subdictionary.... as above\n",
        "*   For each word in A1 and word-pair in A2 dictionaries, sum up total of values in subdictionary, and divide each number by that count, such that each one sums to 1.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xGPcptIdV8Mx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import A\n",
        "pi = {}\n",
        "A1 = {}\n",
        "A2 = {}\n",
        "words = []\n",
        "#sum = 0\n",
        "\n",
        "for line in lines_formatted:\n",
        "    words = line.split(' ')\n",
        "    if '' in words:\n",
        "        words.remove('')\n",
        "    for i in range(len(words)):\n",
        "        if i == 0: #if this is the first word in the line (update pi)\n",
        "            if words[i] in pi: #if it exists in the pi dictionary\n",
        "                pi[words[i]] += 1/len(lines_formatted)\n",
        "            else: #if it does not exist in the pi dictionary\n",
        "                pi.update({words[i]: 1/len(lines_formatted)})\n",
        "        elif i == 1: #if this is the second word in the line (update A1)\n",
        "            if words[i-1] in A1: #if the previous word exists in the A1 dictionary\n",
        "                if words[i] in A1[words[i-1]]: #if the current word exists in the previous word's subdictionary\n",
        "                    A1[words[i-1]][words[i]] += 1\n",
        "                else: #if the current word does not exist in the subdictionary\n",
        "                    A1[words[i-1]].update({words[i]: 1})\n",
        "            else:\n",
        "                A1.update({words[i-1]: {words[i]: 1}})\n",
        "        else: #if this is not the first or second word in the line (update A2)\n",
        "            if (words[i-2],words[i-1]) in A2:\n",
        "                if words[i] in A2[(words[i-2],words[i-1])]:\n",
        "                    A2[(words[i-2],words[i-1])][words[i]] += 1\n",
        "                else:\n",
        "                    A2[(words[i-2],words[i-1])].update({words[i]: 1})\n",
        "            else:\n",
        "                A2.update({(words[i-2],words[i-1]): {words[i]: 1}})\n",
        "\n",
        "for i in A1:\n",
        "    word_count = sum(A1[i].values())\n",
        "    for j in A1[i]:\n",
        "        A1[i][j] = A1[i][j]/word_count\n",
        "\n",
        "for i in A2:\n",
        "    word_count = sum(A2[i].values())\n",
        "    for j in A2[i]:\n",
        "        A2[i][j] = A2[i][j]/word_count"
      ],
      "metadata": {
        "id": "k2mLWWzqV7ia"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Text using pi and A\n",
        "\n",
        "Now generate a poem. For each line, generate a first word using pi, a second word using A2, then generate words following it using A2. If encountering a word which doesn't exist in A2 (that is, it only exists in the training text as the end of a line) then add a full stop and stop generating.\n",
        "\n",
        "generateLine and generatePoem will be functions allowing variable line length and line number."
      ],
      "metadata": {
        "id": "eJh-dmpvqdGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generateLine(line_length):\n",
        "    random_line = []\n",
        "\n",
        "    #generate first word using pi\n",
        "    words = list(pi.keys())\n",
        "    weights = list(pi.values())\n",
        "    random_line.append(random.choices(words,weights)[0])\n",
        "\n",
        "    #generate second work using A1\n",
        "    words = list(A1[random_line[0]].keys())\n",
        "    weights = list(A1[random_line[0]].values())\n",
        "    random_line.append(random.choices(words,weights)[0])\n",
        "\n",
        "    for i in range(line_length-2):\n",
        "        if (random_line[i],random_line[i+1]) not in A2:\n",
        "            random_line.append('.')\n",
        "            break\n",
        "        words = list(A2[(random_line[i],random_line[i+1])].keys())\n",
        "        weights = list(A2[(random_line[i],random_line[i+1])].values())\n",
        "        random_line.append(random.choices(words,weights)[0])\n",
        "    return \" \".join(random_line).replace(' .','.')"
      ],
      "metadata": {
        "id": "M_27Asm01-YV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generatePoem(line_length, line_number):\n",
        "    random_poem = []\n",
        "    for _ in range(line_number):\n",
        "        random_poem.append(generateLine(line_length))\n",
        "    return \"\\n\".join(random_poem)"
      ],
      "metadata": {
        "id": "4oYJF-112UXA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generatePoem(16,4))"
      ],
      "metadata": {
        "id": "COIXM4Wm2ruG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccd360fa-42a3-4ad9-c580-0a9e3717dcc8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "that i journeyed down here .\n",
            "of which it doth now know.\n",
            "admiring natures universal throne.\n",
            "and the giddy stars so legends tell.\n"
          ]
        }
      ]
    }
  ]
}